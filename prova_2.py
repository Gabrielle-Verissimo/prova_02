# -*- coding: utf-8 -*-
"""prova_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L9Q_jAR-7fTXFx3i7xBFA9U4qGN2XWQP
"""

# Aluno(a): Gabrielle da Silva Ver√≠ssimo
# Matr√≠cula:20190096090

from google.colab import drive
drive.mount('/content/drive')

!apt-get update
!apt-get install unrar

#Descompacta Sinais.rar
!unrar x "drive/My Drive/UFPB/Aprendizagem-de-maquina/prova/Sinais.rar"

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import os
import json
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import make_scorer, accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.neural_network import MLPClassifier

"""#Pr√©-processamento dos dados"""

signs = pd.read_csv('/content/sinais.csv', sep=",")

#Retorna as 5 primeiras linhas do arquivo e vemos que h√° 7 colunas
signs.head()

#Vemos que cada coluna tem 2052 valores n√£o nulos menos a coluna 'file_name', ou seja, est√° faltando um nome
signs.info()

#Procura a linha que tem o dado faltante
row_with_missing_data = signs[signs.isnull().any(axis=1)]
row_with_missing_data

# Filtra as linhas da coluna 'sinal' que tem o valor 'Bolsa de Estudos' e a coluna 'interprete' que tem o valor 'Cecilia'
#para saber o padr√£o dos nomes da coluna 'file_name'
rows_bolsa_de_estudos_cecilia = signs[(signs['sinal'] == 'Bolsa de Estudos') & (signs['interprete'] == 'Cecilia')]
rows_bolsa_de_estudos_cecilia

# Preenche a linha com o valor faltante
signs.loc[565, 'file_name'] = "Bolsa de estudo_CS_3.json"
print(signs.loc[565])

#Procurando dados duplicados
dup=signs.duplicated()
sum(dup)

json_folder_path = '/content/Sinais'

all_json_data = []

# L√™ todos os arquivos .json da pasta Sinais e salva os dados junto com o nome do arquivo em um dicionario
for filename in os.listdir(json_folder_path):
    if filename.endswith('.json'):
        file_path = os.path.join(json_folder_path, filename)
        try:
            with open(file_path, 'r') as f:
                data = json.load(f)
                all_json_data.append({'file_name': filename, 'data': data})
        except json.JSONDecodeError:
            print(f"Error decoding JSON from {filename}")
        except FileNotFoundError:
            print(f"Error: {filename} not found.")
        except Exception as e:
            print(f"An error occurred while reading {filename}: {e}")

print(f"Tamanho do array: {len(all_json_data)}.")
print(all_json_data[0])

"""J√° que h√° 2501 arquivos .json, significa que Bolsa de estudo_CS_3.json n√£o existe, ent√£o temos que remover seu registro do sinais.csv ü§°"""

#Excluir a linha com os dados do .json faltante
signs = signs.drop(565)

# Verificando o shape para ver se foi removido com sucesso
signs.shape

"""Reprocessa os dados JSON extraindo as coordenadas dos keypoints e a visibilidade de cada quadro e adiciona a m√©dia (para representar a posi√ß√£o central de cada id) e o desvio padr√£o (representa a varia√ß√£o do movimento)."""

processed_data = []

for item in all_json_data:
    filename = item['file_name']
    json_content = item['data']
    frames = json_content.get('frames', [])
    features = {'file_name': filename}

    if frames:
        # Extrai os keypoints de todos os frames
        all_keypoints = [frame.get('keypoints', []) for frame in frames]

        # Inicializa a lista para guardar as coordenadas e visibilidade de cada id
        keypoint_coords = {} # {id: {'x': [], 'y': [], 'z': [], 'visibility': []}}
        for frame_keypoints in all_keypoints:
            for keypoint in frame_keypoints:
                keypoint_id = keypoint.get('id')
                if keypoint_id is not None:
                    if keypoint_id not in keypoint_coords:
                        keypoint_coords[keypoint_id] = {'x': [], 'y': [], 'z': [], 'visibility': []}

                    keypoint_coords[keypoint_id]['x'].append(keypoint.get('x'))
                    keypoint_coords[keypoint_id]['y'].append(keypoint.get('y'))
                    keypoint_coords[keypoint_id]['z'].append(keypoint.get('z'))
                    keypoint_coords[keypoint_id]['visibility'].append(keypoint.get('visibility'))

        # Calcula a m√©dia e o desvio padr√£o para cada coordenada e a visibilidade em todos os quadros para cada keypoint ID
        for keypoint_id, coords in keypoint_coords.items():
            features[f'keypoint_{keypoint_id}_mean_x'] = np.mean(coords['x']) if coords['x'] else 0
            features[f'keypoint_{keypoint_id}_std_x'] = np.std(coords['x']) if coords['x'] else 0
            features[f'keypoint_{keypoint_id}_mean_y'] = np.mean(coords['y']) if coords['y'] else 0
            features[f'keypoint_{keypoint_id}_std_y'] = np.std(coords['y']) if coords['y'] else 0
            features[f'keypoint_{keypoint_id}_mean_z'] = np.mean(coords['z']) if coords['z'] else 0
            features[f'keypoint_{keypoint_id}_std_z'] = np.std(coords['z']) if coords['z'] else 0
            features[f'keypoint_{keypoint_id}_mean_visibility'] = np.mean(coords['visibility']) if coords['visibility'] else 0
            features[f'keypoint_{keypoint_id}_std_visibility'] = np.std(coords['visibility']) if coords['visibility'] else 0

    processed_data.append(features)

processed_df = pd.DataFrame(processed_data)

processed_df.head()

# Mescla as informa√ß√µes do sinais.csv com os arquivos json correspondentes
combined_data = pd.merge(signs, processed_df, on='file_name', how='inner')

combined_data.head()

combined_data.shape

"""Cria√ß√£o dos conjuntos de treinamento e teste"""

# Exclui 'file_name'e 'interprete' porque n√£o s√£o relevantes para o treinamentos e 'sinais' porque √© o label e vai ficar em y
x = combined_data.drop(['file_name', 'sinal', 'interprete'], axis=1)
y = combined_data['sinal']

# Separa o dataset de treino e o dataset de teste
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=35)

print("Shape de X_train:", x_train.shape)
print("Shape de X_test:", x_test.shape)
print("Shape de y_train:", y_train.shape)
print("Shape de y_test:", y_test.shape)

scaler = StandardScaler()

# Normalizando colunas de x_train
x_train_scaled = scaler.fit_transform(x_train)

# Normalizando colunas de x_test
x_test_scaled = scaler.transform(x_test)

x_train_scaled_df = pd.DataFrame(x_train_scaled, columns=x_train.columns)
x_train_scaled_df.describe()

x_test_scaled_df = pd.DataFrame(x_test_scaled, columns=x_test.columns)
x_test_scaled_df.describe()

"""# Treinamento do modelo de √°rvore de decis√£o (Random Forest)

Configura e executa uma Busca Aleat√≥ria com Valida√ß√£o Cruzada para encontrar os melhores hiperpar√¢metros para um modelo RandomForestClassifier.
"""

# Commented out IPython magic to ensure Python compatibility.

# cria grid search
seed = 15
num_folds = 5
kfold = StratifiedKFold(n_splits=num_folds,random_state=seed,shuffle=True)
scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}

# define os parametros do grid
param_grid = {'n_estimators': [100, 512], #n¬∫ de √°rvores na floresta
             'max_features' : ['sqrt', 'log2', 7], #O n√∫mero de atributos a serem considerados ao procurar a melhor divis√£o em cada n√≥
              'max_depth' : [None, 5, 10], #Ajuda a controlar o overfitting, limita a profundidade m√°xima de cada √°rvore na floresta
              'min_samples_split': [2, 5, 10], #O n√∫mero m√≠nimo de amostras necess√°rias para dividir um n√≥ interno em cada √°rvore
              'min_samples_leaf': [1, 2, 4], #O n√∫mero m√≠nimo de amostras que devem estar em um n√≥ folha em cada √°rvore
              'criterion' : ['entropy','gini'],#define a fun√ß√£o para medir a qualidade de uma divis√£o em cada √°rvore individual
              'class_weight' : ['balanced',None], #Para lidar com classes desbalanceadas
              'warm_start': [False, True],
             'random_state' : [42]
             }

grid = RandomizedSearchCV(RandomForestClassifier(),
                    param_distributions=param_grid,
                    n_iter=100,
                    cv=kfold,
                    scoring=scoring,
                    return_train_score=True,
                    n_jobs=-1,
                    verbose=1,
                    refit="Accuracy")

# %time best_model = grid.fit(x_train_scaled,y_train)

best_log = grid.best_estimator_
print(best_log)
print("_"*40)
print("Score da aprendizagem", np.abs(grid.best_score_))
print("_"*40)
print("*"*40)

"""Usa as bases de teste para medir acur√°cia do modelo"""

predictions = best_log.predict(x_test_scaled)
accuracy = accuracy_score(y_test, predictions)
print("Acur√°cia do teste via accuracy_score:", accuracy )

"""Avalia√ß√£o do modelo com F1-score e Matriz de confus√£o"""

# Calculo F1-score
f1 = f1_score(y_test, predictions, average='weighted')
print(f"F1-score (weighted): {f1}")

# Calculo Matriz de confus√£o
cm = confusion_matrix(y_test, predictions)

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=best_log.classes_, yticklabels=best_log.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""#Modelo KNN"""

# Par√¢metros do algoritmo
k_values = np.array([1,2,3,4,5])
weights = ["uniform","distance"]
algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']
metric = ['euclidean','manhattan','minkowski']

# Quantidade de folds a ser utilizado no Cross-Validation
num_folds = 5

# define os hiperpar√¢metros
parametros = {"n_neighbors":k_values,
              "weights":weights,
              "algorithm":algorithm,
              "metric":metric,
             }

# instancia o modelo
model = KNeighborsClassifier()

# m√©trica de avalia√ß√£o a ser usada
scoring = 'accuracy'

# Grid Search com cross-validation usando StratifiedKFold
kfold = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)
grid = GridSearchCV(estimator=model,
                    param_grid=parametros,
                    scoring=scoring,
                    cv=kfold,
                    n_jobs=-1)

# Commented out IPython magic to ensure Python compatibility.
# treinamento do modelo
# %time best_model = grid.fit(x_train_scaled, y_train)

print("Melhores par√¢metros encontrados:")
print(best_model.best_params_)
print("_"*40)
print("Melhor score de acur√°cia:", np.abs(best_model.best_score_))
print("_"*40)
print("*"*40)

predictions = best_model.predict(x_test_scaled)
accuracy = accuracy_score(y_test, predictions)
print("Acur√°cia do teste via accuracy_score:", accuracy )

# Calculo F1-score
f1 = f1_score(y_test, predictions, average='weighted')
print(f"F1-score (weighted): {f1}")

# Calculo Matriz de confus√£o
cm = confusion_matrix(y_test, predictions)

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=best_model.classes_, yticklabels=best_model.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""#Modelo MLP"""

# Estrutura da rede:
# Camada de Entrada:  25
# Camada Oculta 1: 120 neur√¥nios.
# Camada Oculta 2: 64 neur√¥nios.
# Camada Oculta 3: 32 neur√¥nios.
# Camada Oculta 4: 16 neur√¥nios.
# Camada Oculta 5: 8 neur√¥nios

mlp = MLPClassifier(hidden_layer_sizes=(120, 64, 32, 16, 8), activation="relu", max_iter=100,random_state=1)

mlp.fit(x_train_scaled, y_train)

predictions = mlp.predict(x_test_scaled)
accuracy = accuracy_score(y_test, predictions)
print("Acur√°cia do teste via accuracy_score:", accuracy)

# Calculo F1-score
f1 = f1_score(y_test, predictions, average='weighted')
print(f"F1-score (weighted): {f1}")

# Calculo Matriz de confus√£o
cm = confusion_matrix(y_test, predictions)

plt.figure(figsize=(12, 10))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=mlp.classes_, yticklabels=mlp.classes_)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

"""## Comparativo de Resultados dos Modelos

Com base nos resultados obtidos:

*   **Random Forest:**
    *   Acur√°cia do teste: 0.9800
    *   F1-score (weighted): 0.9804

*   **KNN:**
    *   Acur√°cia do teste: 0.9800
    *   F1-score (weighted): 0.9799

*   **MLP:**
    *   Acur√°cia do teste: 0.9122
    *   F1-score (weighted): 0.9126

Observa-se que os modelos Random Forest e KNN apresentaram resultados de acur√°cia e F1-score muito pr√≥ximos e superiores ao modelo MLP. Isso sugere que para este conjunto de dados e as features extra√≠das, os modelos baseados em √°rvores de decis√£o e vizinhos mais pr√≥ximos tiveram um desempenho melhor do que a rede neural multicamada com a configura√ß√£o utilizada.

#Clusteriza√ß√£o

## Prepara√ß√£o dos dados
"""

# Utiliza One-Hot Encoding na coluna 'interprete'
interprete_encoded = pd.get_dummies(combined_data['interprete'], prefix='interprete')

# Remove as colunas originais 'file_name', 'sinal' e 'interprete'
X_clustering = combined_data.drop(['file_name', 'sinal', 'interprete'], axis=1)

# Concatena as colunas codificadas com as outras features
X_clustering = pd.concat([X_clustering, interprete_encoded], axis=1)

# Normaliza os dados
scaler = StandardScaler()
X_clustering_scaled = scaler.fit_transform(X_clustering)

X_clustering_scaled_df = pd.DataFrame(X_clustering_scaled, columns=X_clustering.columns)

print("Primeiras 5 linhas dos dados de clusteriza√ß√£o normalizados com a coluna 'interprete' codificada:")
X_clustering_scaled_df.head()

"""##k-means"""

from sklearn.cluster import KMeans

inertia = []
for k in range(1, 25):
    kmeans = KMeans(n_clusters=k, random_state=1, n_init=10)
    kmeans.fit(X_clustering_scaled)
    inertia.append(kmeans.inertia_)

# M√©todo do cotovelo (Elbow Method) para encontrar um valor apropriado para K

plt.figure(figsize=(8, 6))
plt.plot(range(1, 25), inertia, marker='o')
plt.xlabel("Numero de Clusters (K)")
plt.ylabel("Inertia")
plt.title("M√©todo do cotovelo para K ideal")
plt.show()

# Usa K=7 para o KMeans sugerido pelo metodo do cotovelo.
kmeans = KMeans(n_clusters=7, random_state=1, n_init=10)

# Normaliza√ß√£o dos dados
kmeans.fit(X_clustering_scaled)

# Armazenaa os r√≥tulos de cluster atribu√≠dos a cada ponto de dados
cluster_labels = kmeans.labels_

print(cluster_labels[:10])

"""##Agrupamento Hier√°rquico mantendo o mesmo valor de K utilizado no K-means.

"""

from sklearn.cluster import AgglomerativeClustering

hac_ward = AgglomerativeClustering(n_clusters=7, linkage='ward')
hac_ward_labels = hac_ward.fit_predict(X_clustering_scaled)

hac_average = AgglomerativeClustering(n_clusters=7, linkage='average')
hac_average_labels = hac_average.fit_predict(X_clustering_scaled)

print("Ward linkage labels:", hac_ward_labels[:10])
print("Average linkage labels:", hac_average_labels[:10])

"""## Avaliar os resultados da clusteriza√ß√£o"""

from sklearn.metrics import silhouette_score

# Calcula pontua√ß√£o Silhouette para K-means
kmeans_silhouette_score = silhouette_score(X_clustering_scaled, cluster_labels)

# Calcula pontua√ß√£o Silhouette score para hierarquico com 'ward' linkage
hac_ward_silhouette_score = silhouette_score(X_clustering_scaled, hac_ward_labels)

# Calcula pontua√ß√£o Silhouette score para hierarquico com 'average' linkage
hac_average_silhouette_score = silhouette_score(X_clustering_scaled, hac_average_labels)

print(f"Silhouette Score for K-means: {kmeans_silhouette_score}")
print(f"Silhouette Score for Hierarchical (Ward): {hac_ward_silhouette_score}")
print(f"Silhouette Score for Hierarchical (Average): {hac_average_silhouette_score}")

"""## Comparativo dos Resultados de Clusteriza√ß√£o

O Silhouette Score mede qu√£o similar um objeto √© ao seu pr√≥prio cluster (coes√£o) comparado com outros clusters (separa√ß√£o). Um score mais alto indica que o objeto est√° bem compat√≠vel com seu pr√≥prio cluster e mal compat√≠vel com clusters vizinhos. O score varia de -1 a 1, onde:

*   Scores pr√≥ximos de +1 indicam que as amostras est√£o bem distantes dos clusters vizinhos.
*   Scores pr√≥ximos de 0 indicam que as amostras est√£o perto do limite de decis√£o entre dois clusters vizinhos.
*   Scores negativos indicam que as amostras podem ter sido atribu√≠das ao cluster errado.

Aqui est√£o os Silhouette Scores obtidos para cada m√©todo:

*   **K-means:** `0.1629712322244504`
*   **Agrupamento Hier√°rquico (Ward):** `0.15276166737450614`
*   **Agrupamento Hier√°rquico (Average):** `0.38469169110934914`

**An√°lise dos Resultados:**

Com base nos Silhouette Scores, o **Agrupamento Hier√°rquico com o m√©todo de liga√ß√£o "Average"** obteve o melhor desempenho (`0.3847`), indicando que seus clusters s√£o mais bem definidos e separados em compara√ß√£o com os outros m√©todos testados.

O K-means (`0.1630`) e o Agrupamento Hier√°rquico com "Ward" linkage (`0.1528`) apresentaram scores de Silhueta semelhantes e consideravelmente mais baixos que o "Average" linkage, sugerindo que os clusters formados por esses m√©todos n√£o s√£o t√£o claramente separados.

√â importante notar que, mesmo o maior Silhouette Score (`0.3847`) n√£o √© muito alto (um score mais pr√≥ximo de 1 seria ideal), o que pode indicar que os clusters n√£o s√£o extremamente distintos nos dados, ou que as features utilizadas n√£o s√£o ideais para separar os sinais em grupos muito coesos e bem separados usando esses algoritmos de clusteriza√ß√£o. No entanto, entre os m√©todos avaliados, o Agrupamento Hier√°rquico com "Average" linkage foi o que apresentou o melhor resultado segundo esta m√©trica.

## Visualizando a distribui√ß√£o dos clusters com PCA
"""

from sklearn.decomposition import PCA

# Reduz a dimensionalidade para 2 componentes principais usando PCA
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_clustering_scaled)

# Cria um DataFrame com os resultados do PCA e os r√≥tulos de cluster do K-means
pca_df = pd.DataFrame(X_pca, columns=['PCA1', 'PCA2'])
pca_df['Cluster'] = cluster_labels # Usando os r√≥tulos do K-means

# Plota a distribui√ß√£o dos clusters nas duas primeiras componentes principais
plt.figure(figsize=(10, 8))
sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=pca_df, palette='viridis', legend='full')
plt.title('Distribui√ß√£o dos Clusters (K-means) ap√≥s PCA')
plt.xlabel('Componente Principal 1')
plt.ylabel('Componente Principal 2')
plt.grid(True)
plt.show()